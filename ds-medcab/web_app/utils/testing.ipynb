{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import dotenv\n",
    "from os import getenv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from json import loads\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsTransformer\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer():\n",
    "    def __init__(self):\n",
    "        # try to load data from .env\n",
    "\n",
    "        self.load_data()\n",
    "\n",
    "        self.tokenizer = Tokenizer(num_words=1000, lower=True)\n",
    "        return\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"A function that takes the DATABASE_URL and fetches the contents of the\n",
    "        strain_info table then saves it to a df\n",
    "        \"\"\"\n",
    "        dotenv.load_dotenv()\n",
    "        alt = 'DATABASE_URL'\n",
    "        db_url = getenv(\"DATASOURCE\", default=alt)\n",
    "        \n",
    "        engine = create_engine(db_url)\n",
    "        df = pd.read_sql(\"SELECT * FROM strain_info\", engine)\n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "    def transform(self, document: pd.DataFrame, negative: list, ignore: list) -> pd.DataFrame:\n",
    "        \"\"\"A function that takes the document input and transforms it into a MinMax\n",
    "        scaled DataFrame that represents the term frequency matrix.\n",
    "        this method adds the dtm's for each feature then subtracts the neg feature's dtm\n",
    "        then scales the data with a MinMaxScalar from sklearn.preprocessing\n",
    "        Arguments:\n",
    "        -------------\n",
    "        document {list} : An array like list of strings representing a document to be transformed\n",
    "        negitive {list} : the list of negitive features to use in calculating the dtm products\n",
    "        ignore {list} : a list of features to ignore in the dtm product\n",
    "        Returns:\n",
    "        -------------\n",
    "        combined_scaled {pd.DataFrame} : A dataframe of the transformed document's tfidf\n",
    "        \"\"\"\n",
    "\n",
    "        dtm = [0] * 1000\n",
    "\n",
    "        for i in document.columns:\n",
    "            if i in ignore:\n",
    "                pass\n",
    "            else:\n",
    "                # takes the document term frequency and if it is\n",
    "                # a neg feature then we want to subtract  it from the combined dtm\n",
    "                if i in negative:\n",
    "                    dtm -= self.find_dtm(document[i])\n",
    "                # otherwise i want to add it to the combined dtm\n",
    "                else:\n",
    "                    dtm += self.find_dtm(document[i])\n",
    "\n",
    "        mm = MinMaxScaler()\n",
    "        combined_scaled_values = mm.fit_transform(dtm)\n",
    "        combined_scaled_columns = dtm.columns.tolist()\n",
    "        combined_scaled = pd.DataFrame(combined_scaled_values,\n",
    "                                       columns=combined_scaled_columns)\n",
    "        combined_scaled.fillna(0, inplace=True)\n",
    "        return combined_scaled, document.index.tolist()\n",
    "\n",
    "    def find_dtm(self, feature):\n",
    "        \"\"\"A function to take a feature and tokenize then return a tfidf df of that input\n",
    "        \"\"\"\n",
    "        self.tokenizer.fit_on_texts(feature)\n",
    "        a = self.tokenizer.texts_to_matrix(feature, mode='tfidf')\n",
    "        config = self.tokenizer.get_config()\n",
    "        feature_names = json_normalize(loads(\n",
    "            config['word_index'])).columns.tolist()\n",
    "        dtm = pd.DataFrame(a)\n",
    "        return dtm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = ['negative']\n",
    "ignore = []\n",
    "user_transformed, y = tr.transform(document=pd.DataFrame({'name': \"blue berry kush\",\n",
    "                  'race': 'sativa',\n",
    "                  'flavors': ['blueberry', 'sweet'],\n",
    "                  'negative': ['dry mouth', 'dry eyes'],\n",
    "                  'positive': ['creativity', 'stress'],\n",
    "                  'medical': ['ptsd', 'stress'],\n",
    "                  'description': \"blueberry kush my dude blueberry_kush:10, whitewhidow:10 \",\n",
    "                  }),negative=negative, ignore=ignore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0    996\n1.0      3\n1.0      1\nName: 0, dtype: int64"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "user_transformed.iloc[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsTransformer()"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsTransformer\n",
    "knn = KNeighborsTransformer()\n",
    "X_train,y_train = tr.transform(tr.df,negative,ignore)\n",
    "\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./transformer.pickle','wb') as fp:\n",
    "    pickle.dump(tr, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([[2.40560978, 2.55181968, 2.60670559, 2.63466242, 2.63672392],\n        [2.34029684, 2.44410932, 2.48769509, 2.49228827, 2.52441853]]),\n array([[ 138,  156,  803,  133,  170],\n        [ 136,  133,  130, 1458, 1452]]))"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "knn.kneighbors(X=user_transformed,n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "index                                       170\nid                                          234\nname                     Bhang Triple Berry Goo\nrace                                     indica\nflavors         ['Berry', 'Apple', 'Blueberry']\npositive       ['Relaxed', 'Euphoric', 'Happy']\nnegative              ['Dry Mouth', 'Dry Eyes']\nmedical             ['Fatigue', 'Eye Pressure']\ndescription                              [None]\nName: 170, dtype: object"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "tr.df.iloc[170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./transformer.pickle','rb') as fp:\n",
    "    tr = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "__main__.Transformer"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "type(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitthrowcondac6bd6c5b69534af0ae472775a9c93db0",
   "display_name": "Python 3.8.2 64-bit ('throw': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}